{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN-PyT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Oohb8pmyeNOO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQLnHK9jJwrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os,time,itertools,pickle,imageio\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0Gh0dPiigMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch as t\n",
        "from torch import cuda,nn,optim,utils\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets,transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P8YV4_-7xNsh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#DCGAN Model (Radford et.al 2015)"
      ]
    },
    {
      "metadata": {
        "id": "lVw3E5WUjuSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ThePolice\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "    # weight_init... for stable gradient flow across layers\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, input):\n",
        "        x = F.leaky_relu(self.conv1(input), 0.2)             #LeakyReLU in all layers except last\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
        "        x = F.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x\n",
        "      \n",
        "#TheCulprit\n",
        "\n",
        "class generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d):\n",
        "        super(generator, self).__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)     #100-d latent space vector\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, input):\n",
        "        # x = F.relu(self.deconv1(input))\n",
        "        x = F.relu(self.deconv1_bn(self.deconv1(input)))  #ReLU all layers except last where tanh used\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = F.tanh(self.deconv5(x))\n",
        "\n",
        "        return x\n",
        "      \n",
        "#WeightInitialiser\n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJ3GA2UvyQPn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Utilities"
      ]
    },
    {
      "metadata": {
        "id": "5Q1dw-dLvr6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create Folder\n",
        "if not os.path.isdir('MNIST_DCGAN_results'):\n",
        "    os.mkdir('MNIST_DCGAN_results')\n",
        "if not os.path.isdir('MNIST_DCGAN_results/Random_results'):\n",
        "    os.mkdir('MNIST_DCGAN_results/Random_results')\n",
        "if not os.path.isdir('MNIST_DCGAN_results/Fixed_results'):\n",
        "    os.mkdir('MNIST_DCGAN_results/Fixed_results')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hQcykW1RzO8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Stackoverflow Stuff :P\n",
        "\n",
        "fixed_z = Variable(torch.randn((5 * 5, 100)).view(-1, 100, 1, 1).cuda(), volatile=True) \n",
        "def show_result(num_epoch, show = False, save = False, path = 'result.png', isFix=False):\n",
        "    \n",
        "    z = torch.randn((5*5, 100)).view(-1, 100, 1, 1)\n",
        "    z = Variable(z.cuda(), volatile=True)\n",
        "\n",
        "    g.eval() #EvalMode\n",
        "    \n",
        "    if isFix:\n",
        "        test_images = g(fixed_z)\n",
        "    else:\n",
        "        test_images = g(z)\n",
        "    \n",
        "    g.train() \n",
        "\n",
        "    size_figure_grid = 5\n",
        "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
        "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
        "        ax[i, j].get_xaxis().set_visible(False)\n",
        "        ax[i, j].get_yaxis().set_visible(False)\n",
        "\n",
        "    for k in range(5*5):\n",
        "        i = k // 5\n",
        "        j = k % 5\n",
        "        ax[i, j].cla()\n",
        "        ax[i, j].imshow(test_images[k, 0].cpu().data.numpy(), cmap='gray')\n",
        "\n",
        "    label = 'Epoch {0}'.format(num_epoch)\n",
        "    fig.text(0.5, 0.04, label, ha='center')\n",
        "    plt.savefig(path)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1ucDHg3tnW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training Plotter\n",
        "\n",
        "def train_plot(hist, show = False, save = False, path = 'Train_plot.png'):\n",
        "    \n",
        "    x = range(len(hist['D_loss']))\n",
        "\n",
        "    y1 = hist['D_loss']\n",
        "    y2 = hist['G_loss']\n",
        "\n",
        "    plt.plot(x, y1, label='D_loss')\n",
        "    plt.plot(x, y2, label='G_loss')\n",
        "\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(path)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wHUP1sMEyV3m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#As mentioned in the paper\n",
        "param = {\n",
        "    \"batch_sz\" : 128,\n",
        "    \"lr\" : 0.0002,\n",
        "    \"beta\" : 0.5,\n",
        "    \"img_size\" : 64}\n",
        "\n",
        "tr_epch = 15\n",
        "\n",
        "#data transforms\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(param[\"img_size\"]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "#Load MNIST\n",
        "train_loader = utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
        "    batch_size=param[\"batch_sz\"], shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hM5ZvC9H8oYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model_init\n",
        "g = generator(128)\n",
        "d = discriminator(128)\n",
        "g.weight_init(mean=0.0, std=0.02)\n",
        "d.weight_init(mean=0.0, std=0.02)\n",
        "\n",
        "#cost function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "if cuda.is_available() :\n",
        "  g.cuda() \n",
        "  d.cuda()\n",
        "  criterion.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnJJmAGy_bux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "g_optim = optim.Adam(g.parameters(), lr=param[\"lr\"], betas=(param[\"beta\"], 0.999))\n",
        "d_optim = optim.Adam(d.parameters(), lr=param[\"lr\"], betas=(param[\"beta\"], 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G05RHOVmJEaW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Train Iterator"
      ]
    },
    {
      "metadata": {
        "id": "N5GsBos6dcSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DejaVu\n",
        "hist = {}\n",
        "hist['D_loss'] = []\n",
        "hist['G_loss'] = []\n",
        "hist['per_epoch_time'] = []\n",
        "hist['tot_time'] = []\n",
        "num_iter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DoDYeSaGg5P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Training Starts Now\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(tr_epch) :\n",
        "  \n",
        "  epoch_start_time = time.time()\n",
        "  d_loss = []\n",
        "  g_loss = []\n",
        "  \n",
        "  for i,data in enumerate(train_loader) : \n",
        "  \n",
        "    y_real = t.ones(param[\"batch_sz\"])   #Alternatively t.ones(data[0].size(0))\n",
        "    y_fake = t.zeros(param[\"batch_sz\"])\n",
        "    x_real = data[0]\n",
        "    z_d = t.randn((param[\"batch_sz\"], 100)).view(-1, 100, 1, 1) #Uniform distribution\n",
        "    z_g = t.randn((param[\"batch_sz\"], 100)).view(-1, 100, 1, 1) #Uniform distribution\n",
        "    \n",
        "    if cuda.is_available() :\n",
        "      #Variable is autograd compliant as of 0.4.1\n",
        "      x_real,y_real,y_fake,z_d,z_g = Variable(x_real.cuda()),Variable(y_real.cuda()),Variable(y_fake.cuda()),Variable(z_d.cuda()),Variable(z_g.cuda())\n",
        "    \n",
        "    #Police Training\n",
        "    \n",
        "    #Discriminator Loss A (Classifies real samples as real....pretty intuitive)\n",
        "    D_result = d(x_real).squeeze()\n",
        "    D_loss_A = criterion(D_result,y_real)\n",
        "    \n",
        "    #Discriminator loss B (classifies fake samples as fake)\n",
        "    D_result = d(g(z_d)).squeeze()\n",
        "    D_loss_B = criterion(D_result,y_fake)\n",
        "    \n",
        "    #Total Discriminator Loss = Loss A + Loss B\n",
        "    D_loss_total = D_loss_A + D_loss_B\n",
        "    d_loss.append(D_loss_total.data[0])   #Future Use\n",
        "    \n",
        "    d.zero_grad()\n",
        "    D_loss_total.backward()\n",
        "    d_optim.step()\n",
        "    \n",
        "    #Culprit Training\n",
        "    \n",
        "    #Generator Loss (generates real looking fake samples)\n",
        "    G_result = d(g(z_g)).squeeze()\n",
        "    G_loss_total = criterion(G_result,y_real)\n",
        "    g_loss.append(G_loss_total.data[0])\n",
        "    \n",
        "    g.zero_grad()\n",
        "    G_loss_total.backward()\n",
        "    g_optim.step()\n",
        "    \n",
        "    num_iter += 1\n",
        "  \n",
        "  epoch_end_time = time.time()\n",
        "  per_epoch_time = epoch_end_time - epoch_start_time\n",
        "  print('[%d/%d] - ptime:%.2f, loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), tr_epch, per_epoch_time, torch.mean(torch.FloatTensor(d_loss)),\n",
        "                                                              torch.mean(torch.FloatTensor(g_loss))))\n",
        "  hist['D_loss'].append(torch.mean(torch.FloatTensor(d_loss)))\n",
        "  hist['G_loss'].append(torch.mean(torch.FloatTensor(g_loss)))\n",
        "  hist['per_epoch_times'].append(per_epoch_time)\n",
        "  \n",
        "  #Showing generator output per epoch\n",
        "  p = 'MNIST_DCGAN_results/Random_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
        "  fixed_p = 'MNIST_DCGAN_results/Fixed_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
        "  show_result((epoch+1), save=True, path=p, isFix=False)\n",
        "  show_result((epoch+1), save=True, path=fixed_p, isFix=True)\n",
        "  \n",
        "#Iteration Info  \n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "hist['tot_time'].append(total_time)\n",
        "print(\"Avg per epoch time: %.2f, total %d epochs time: %.2f\" % (torch.mean(torch.FloatTensor(hist['per_epoch_ptimes'])), tr_epch, total_time))\n",
        "print(\"Training over!..\")\n",
        "\n",
        "#Saving model state\n",
        "torch.save(g.state_dict(), \"MNIST_DCGAN_results/g_param.pkl\")\n",
        "torch.save(d.state_dict(), \"MNIST_DCGAN_results/d_param.pkl\")\n",
        "with open('MNIST_DCGAN_results/train_hist.pkl', 'wb') as f:\n",
        "    pickle.dump(hist, f)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hb8nYvi7w-Nt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Results"
      ]
    },
    {
      "metadata": {
        "id": "Rot8GDRPw2bU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_plot(hist, save=True, path='MNIST_DCGAN_results/MNIST_DCGAN_train_hist.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmpiCYnkxjsr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fun Stuff\n",
        "images = []\n",
        "\n",
        "\n",
        "for e in range(tr_epch):\n",
        "    img_name = 'MNIST_DCGAN_results/Fixed_results/MNIST_DCGAN_' + str(e + 1) + '.png'\n",
        "    images.append(imageio.imread(img_name))\n",
        "    \n",
        "    \n",
        "imageio.mimsave('MNIST_DCGAN_results/generation_animation.gif', images, fps=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}