{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQLnHK9jJwrU"
   },
   "outputs": [],
   "source": [
    "import os,time,itertools,pickle,imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0Gh0dPiigMh"
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import cuda,nn,optim,utils\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8YV4_-7xNsh"
   },
   "source": [
    "#DCGAN Model (Radford et.al 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVw3E5WUjuSh"
   },
   "outputs": [],
   "source": [
    "#ThePolice\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
    "\n",
    "    # weight_init... for stable gradient flow across layers\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)             #LeakyReLU in all layers except last\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        #x = t.sigmoid(self.conv5(x))                        The output of D is no longer a probability now. \n",
    "        x = self.conv5(x)\n",
    "\n",
    "        return x\n",
    "      \n",
    "#TheCulprit\n",
    "\n",
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d):\n",
    "        super(generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)     #100-d latent space vector\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)                     \n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:   \n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))  #ReLU all layers except last where tanh used\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))      \n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))      \n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = t.tanh(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "      \n",
    "#WeightInitialiser\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ3GA2UvyQPn"
   },
   "source": [
    "#Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Q1dw-dLvr6i"
   },
   "outputs": [],
   "source": [
    "#Create Folder\n",
    "if not os.path.isdir('MNIST_DCGAN_results'):\n",
    "    os.mkdir('MNIST_DCGAN_results')\n",
    "if not os.path.isdir('MNIST_DCGAN_results/Random_results'):\n",
    "    os.mkdir('MNIST_DCGAN_results/Random_results')\n",
    "if not os.path.isdir('MNIST_DCGAN_results/Fixed_results'):\n",
    "    os.mkdir('MNIST_DCGAN_results/Fixed_results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQcykW1RzO8a"
   },
   "outputs": [],
   "source": [
    "#Stackoverflow Stuff :P\n",
    "\n",
    "fixed_z = Variable(t.Tensor(5 * 5, 100).normal_().view(-1, 100, 1, 1).cuda())  #Mod-2\n",
    "def show_result(num_epoch, show = False, save = False, path = 'result.png', isFix=False):\n",
    "    \n",
    "    z = t.Tensor(5*5, 100).normal_().view(-1, 100, 1, 1)                       #Mod-2\n",
    "    z = Variable(z.cuda())\n",
    "\n",
    "    g.eval() #EvalMode\n",
    "    \n",
    "    if isFix:\n",
    "        test_images = g(fixed_z)\n",
    "    else:\n",
    "        test_images = g(z)\n",
    "    \n",
    "    g.train() \n",
    "\n",
    "    size_figure_grid = 5\n",
    "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "        ax[i, j].get_xaxis().set_visible(False)\n",
    "        ax[i, j].get_yaxis().set_visible(False)\n",
    "\n",
    "    for k in range(5*5):\n",
    "        i = k // 5\n",
    "        j = k % 5\n",
    "        ax[i, j].cla()\n",
    "        ax[i, j].imshow(test_images[k, 0].cpu().data.numpy(), cmap='gray')\n",
    "\n",
    "    label = 'Epoch {0}'.format(num_epoch)\n",
    "    fig.text(0.5, 0.04, label, ha='center')\n",
    "    plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1ucDHg3tnW3"
   },
   "outputs": [],
   "source": [
    "#Training Plotter\n",
    "\n",
    "def train_plot(hist, show = False, save = False, path = 'Train_plot.png'):\n",
    "    \n",
    "    x = range(len(hist['D_loss']))\n",
    "\n",
    "    y1 = hist['D_loss']\n",
    "    y2 = hist['G_loss']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "wHUP1sMEyV3m",
    "outputId": "8371cd17-39a0-4bc4-bd6c-172d9f5b3f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#As mentioned in the paper\n",
    "param = {\n",
    "    \"batch_sz\" : 128,\n",
    "    \"lr\" : 0.0002,\n",
    "    \"beta\" : 0.5,\n",
    "    \"img_size\" : 64,\n",
    "    \"lrD\" : 0.00005,\n",
    "    \"lrG\" : 0.00005,\n",
    "    \"clamp-lower\" : 0.01,\n",
    "    \"clamp-upper\" : 0.01,\n",
    "    \"d_iter\" : 5\n",
    "}\n",
    "\n",
    "tr_epch = 75\n",
    "\n",
    "#data transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(param[\"img_size\"]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "#Load MNIST\n",
    "train_loader = utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "    batch_size=param[\"batch_sz\"], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hM5ZvC9H8oYO"
   },
   "outputs": [],
   "source": [
    "#Model_init\n",
    "g = generator(64)\n",
    "d = discriminator(64)\n",
    "g.weight_init(mean=0.0, std=0.02)\n",
    "d.weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "#cost function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "if cuda.is_available() :\n",
    "  g.cuda() \n",
    "  d.cuda()\n",
    "  criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnJJmAGy_bux"
   },
   "outputs": [],
   "source": [
    "g_optim = optim.RMSprop(g.parameters(), lr=param[\"lrG\"]) \n",
    "d_optim = optim.RMSprop(d.parameters(), lr=param[\"lrD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G05RHOVmJEaW"
   },
   "source": [
    "#Train Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5GsBos6dcSn"
   },
   "outputs": [],
   "source": [
    "#DejaVu\n",
    "hist = {}\n",
    "hist['D_loss'] = []\n",
    "hist['G_loss'] = []\n",
    "hist['per_epoch_time'] = []\n",
    "hist['tot_time'] = []\n",
    "hist['Wasserstein_D'] = []\n",
    "num_iter = 0\n",
    "\n",
    "one = t.Tensor([1])\n",
    "m_one = one * -1\n",
    "if cuda.is_available() :\n",
    "    one,m_one = Variable(one.cuda()),Variable(m_one.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "_DoDYeSaGg5P",
    "outputId": "67e6464e-97cd-4d7a-d16b-c4292bb62e2b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts Now\n",
      "[1/75] - ptime:367.48, loss_d: 1.493, loss_g: 0.720\n",
      "[2/75] - ptime:370.64, loss_d: 1.498, loss_g: 0.720\n",
      "[3/75] - ptime:371.56, loss_d: 1.515, loss_g: 0.736\n",
      "[4/75] - ptime:371.40, loss_d: 1.330, loss_g: 0.664\n",
      "[5/75] - ptime:371.47, loss_d: 1.117, loss_g: 0.569\n",
      "[6/75] - ptime:371.86, loss_d: 1.096, loss_g: 0.544\n",
      "[7/75] - ptime:371.63, loss_d: 1.068, loss_g: 0.529\n",
      "[8/75] - ptime:372.08, loss_d: 1.049, loss_g: 0.518\n",
      "[9/75] - ptime:372.00, loss_d: 1.050, loss_g: 0.512\n",
      "[10/75] - ptime:372.13, loss_d: 1.049, loss_g: 0.515\n",
      "[11/75] - ptime:371.77, loss_d: 1.040, loss_g: 0.512\n",
      "[12/75] - ptime:371.52, loss_d: 1.040, loss_g: 0.506\n",
      "[13/75] - ptime:371.63, loss_d: 1.040, loss_g: 0.507\n",
      "[14/75] - ptime:371.77, loss_d: 1.036, loss_g: 0.507\n",
      "[15/75] - ptime:371.46, loss_d: 1.036, loss_g: 0.505\n",
      "[16/75] - ptime:372.00, loss_d: 1.028, loss_g: 0.500\n",
      "[17/75] - ptime:372.29, loss_d: 1.019, loss_g: 0.498\n",
      "[18/75] - ptime:372.03, loss_d: 1.018, loss_g: 0.498\n",
      "[19/75] - ptime:371.65, loss_d: 1.016, loss_g: 0.488\n",
      "[20/75] - ptime:371.62, loss_d: 1.013, loss_g: 0.490\n",
      "[21/75] - ptime:371.64, loss_d: 1.005, loss_g: 0.487\n",
      "[22/75] - ptime:371.67, loss_d: 1.004, loss_g: 0.486\n",
      "[23/75] - ptime:371.41, loss_d: 0.997, loss_g: 0.481\n",
      "[24/75] - ptime:371.44, loss_d: 0.992, loss_g: 0.480\n",
      "[25/75] - ptime:371.68, loss_d: 0.987, loss_g: 0.477\n",
      "[26/75] - ptime:372.25, loss_d: 0.984, loss_g: 0.476\n",
      "[27/75] - ptime:371.56, loss_d: 0.972, loss_g: 0.474\n",
      "[28/75] - ptime:371.57, loss_d: 0.970, loss_g: 0.470\n",
      "[29/75] - ptime:371.47, loss_d: 0.965, loss_g: 0.466\n",
      "[30/75] - ptime:371.64, loss_d: 0.960, loss_g: 0.465\n",
      "[31/75] - ptime:371.61, loss_d: 0.953, loss_g: 0.460\n",
      "[32/75] - ptime:371.53, loss_d: 0.950, loss_g: 0.460\n",
      "[33/75] - ptime:371.68, loss_d: 0.945, loss_g: 0.458\n",
      "[34/75] - ptime:371.54, loss_d: 0.940, loss_g: 0.456\n",
      "[35/75] - ptime:372.13, loss_d: 0.936, loss_g: 0.452\n",
      "[36/75] - ptime:371.51, loss_d: 0.930, loss_g: 0.448\n",
      "[37/75] - ptime:371.48, loss_d: 0.928, loss_g: 0.448\n",
      "[38/75] - ptime:371.46, loss_d: 0.922, loss_g: 0.445\n",
      "[39/75] - ptime:371.47, loss_d: 0.920, loss_g: 0.445\n",
      "[40/75] - ptime:371.28, loss_d: 0.912, loss_g: 0.439\n",
      "[41/75] - ptime:371.43, loss_d: 0.904, loss_g: 0.439\n",
      "[42/75] - ptime:371.38, loss_d: 0.903, loss_g: 0.440\n",
      "[43/75] - ptime:371.36, loss_d: 0.896, loss_g: 0.433\n",
      "[44/75] - ptime:371.48, loss_d: 0.893, loss_g: 0.436\n",
      "[45/75] - ptime:371.13, loss_d: 0.890, loss_g: 0.435\n",
      "[46/75] - ptime:371.45, loss_d: 0.885, loss_g: 0.433\n",
      "[47/75] - ptime:371.07, loss_d: 0.880, loss_g: 0.430\n",
      "[48/75] - ptime:371.60, loss_d: 0.881, loss_g: 0.429\n",
      "[49/75] - ptime:371.68, loss_d: 0.873, loss_g: 0.426\n",
      "[50/75] - ptime:371.08, loss_d: 0.869, loss_g: 0.425\n",
      "[51/75] - ptime:371.27, loss_d: 0.863, loss_g: 0.423\n",
      "[52/75] - ptime:371.14, loss_d: 0.862, loss_g: 0.422\n",
      "[53/75] - ptime:371.01, loss_d: 0.856, loss_g: 0.420\n",
      "[54/75] - ptime:371.07, loss_d: 0.851, loss_g: 0.417\n",
      "[55/75] - ptime:370.99, loss_d: 0.847, loss_g: 0.417\n",
      "[56/75] - ptime:371.05, loss_d: 0.846, loss_g: 0.414\n",
      "[57/75] - ptime:371.14, loss_d: 0.843, loss_g: 0.412\n",
      "[58/75] - ptime:371.20, loss_d: 0.836, loss_g: 0.410\n",
      "[59/75] - ptime:371.08, loss_d: 0.835, loss_g: 0.411\n",
      "[60/75] - ptime:370.98, loss_d: 0.833, loss_g: 0.408\n",
      "[61/75] - ptime:371.09, loss_d: 0.825, loss_g: 0.408\n",
      "[62/75] - ptime:370.62, loss_d: 0.823, loss_g: 0.405\n",
      "[63/75] - ptime:370.80, loss_d: 0.823, loss_g: 0.404\n",
      "[64/75] - ptime:370.96, loss_d: 0.817, loss_g: 0.402\n",
      "[65/75] - ptime:370.96, loss_d: 0.813, loss_g: 0.400\n",
      "[66/75] - ptime:370.89, loss_d: 0.811, loss_g: 0.401\n",
      "[67/75] - ptime:370.88, loss_d: 0.811, loss_g: 0.398\n",
      "[68/75] - ptime:370.92, loss_d: 0.804, loss_g: 0.397\n",
      "[69/75] - ptime:370.93, loss_d: 0.801, loss_g: 0.394\n",
      "[70/75] - ptime:370.66, loss_d: 0.801, loss_g: 0.395\n",
      "[71/75] - ptime:370.52, loss_d: 0.798, loss_g: 0.393\n",
      "[72/75] - ptime:370.41, loss_d: 0.794, loss_g: 0.394\n",
      "[73/75] - ptime:370.46, loss_d: 0.792, loss_g: 0.390\n",
      "[74/75] - ptime:370.64, loss_d: 0.790, loss_g: 0.390\n",
      "[75/75] - ptime:370.52, loss_d: 0.786, loss_g: 0.390\n",
      "Avg per epoch time: 371.31, total 75 epochs time: 27941.46\n",
      "Training over!..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training Starts Now\")\n",
    "\n",
    "start_time = time.time()\n",
    "g_iter = 0\n",
    "\n",
    "for epoch in range(tr_epch) :\n",
    "    epoch_start_time = time.time()\n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    \n",
    "    \n",
    "        \n",
    "    for i,data in enumerate(train_loader) : \n",
    "        x_real = data[0]\n",
    "        z_d = t.Tensor(data[0].size()[0], 100).normal_().view(-1, 100, 1, 1)#Uniform distribution     #Mod-2\n",
    "      # z_g = t.randn((data[0].size()[0], 100)).view(-1, 100, 1, 1) #Uniform distribution\n",
    "    \n",
    "        if cuda.is_available() :\n",
    "            #Variable is autograd compliant as of 0.4.1\n",
    "            x_real,z_d = Variable(x_real.cuda()),Variable(z_d.cuda())\n",
    "        \n",
    "        \n",
    "        #Police Training(Train discriminator d_iter times while training the generator 1 time)\n",
    "        for p in d.parameters() :\n",
    "            p.requires_grad = True\n",
    "        \n",
    "        for i in range(param[\"d_iter\"]) :\n",
    "            d_loss_temp = []\n",
    "            d.zero_grad()\n",
    "            \n",
    "            for p in d.parameters() :\n",
    "                p.data.clamp_(-param[\"clamp-upper\"],param[\"clamp-upper\"])\n",
    "            #Discriminator loss A\n",
    "            D_loss_A = d(x_real)\n",
    "            D_loss_A = D_loss_A.mean(0).view(-1)\n",
    "            D_loss_A.backward(one)\n",
    "            \n",
    "            #Discriminator loss B\n",
    "            D_loss_B = d(g(z_d))\n",
    "            D_loss_B = D_loss_B.mean(0).view(-1)\n",
    "            D_loss_B.backward(m_one)\n",
    "            \n",
    "            #Total Discriminator Loss\n",
    "            D_loss_total = D_loss_B - D_loss_A\n",
    "            Wasserstein_D = -D_loss_total\n",
    "            d_loss_temp.append(D_loss_total.item())\n",
    "            d_optim.step()\n",
    "    \n",
    "        #Culprit Training\n",
    "        for p in d.parameters() :\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        #Generator Loss (generates real looking fake samples)\n",
    "        G_loss_total = d(g(z_d))\n",
    "        G_loss_total =  G_loss_total.mean(0).view(-1)        #Mod1 : loss function gen\n",
    "        \n",
    "        g_loss.append(G_loss_total.item())\n",
    "        d_loss.append(t.mean(t.FloatTensor(d_loss_temp)))\n",
    "        g.zero_grad()\n",
    "        G_loss_total.backward(one)\n",
    "        g_optim.step()\n",
    "    \n",
    "        num_iter += 1\n",
    "  \n",
    "    epoch_end_time = time.time()\n",
    "    per_epoch_time = epoch_end_time - epoch_start_time\n",
    "    print('[%d/%d] - ptime:%.2f, loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), tr_epch, per_epoch_time, t.mean(t.FloatTensor(d_loss)),\n",
    "                                                              t.mean(t.FloatTensor(g_loss))))\n",
    "    hist['D_loss'].append(t.mean(t.FloatTensor(d_loss)))\n",
    "    hist['G_loss'].append(t.mean(t.FloatTensor(g_loss)))\n",
    "    hist['per_epoch_time'].append(per_epoch_time)\n",
    "  \n",
    "    #Showing generator output per epoch\n",
    "    p = 'MNIST_DCGAN_results/Random_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
    "    fixed_p = 'MNIST_DCGAN_results/Fixed_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
    "    show_result((epoch+1), save=True, path=p, isFix=False)\n",
    "    show_result((epoch+1), save=True, path=fixed_p, isFix=True)\n",
    "  \n",
    "#Iteration Info  \n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "hist['tot_time'].append(total_time)\n",
    "print(\"Avg per epoch time: %.2f, total %d epochs time: %.2f\" % (t.mean(t.FloatTensor(hist['per_epoch_time'])), tr_epch, total_time))\n",
    "print(\"Training over!..\")\n",
    "\n",
    "#Saving model state\n",
    "t.save(g.state_dict(), \"MNIST_DCGAN_results/g_param.pkl\")\n",
    "t.save(d.state_dict(), \"MNIST_DCGAN_results/d_param.pkl\")\n",
    "with open('MNIST_DCGAN_results/train_hist.pkl', 'wb') as f:\n",
    "    pickle.dump(hist, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sdNgAHtit3bV"
   },
   "source": [
    "Conflicting nature of losses (as in pretty evident from above train lapse) is the reason why these networks are \"**adversarial**\" in nature. <br> <br>\n",
    "\n",
    "Training seems to be pretty stable as opposed to traditional GAN training. <br>\n",
    "\n",
    "Total train time for 75 epochs (GTX 1070 8GB GPU) ~ **8 Hours**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hb8nYvi7w-Nt"
   },
   "source": [
    "#Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "Rot8GDRPw2bU",
    "outputId": "d882d4ac-7e85-435d-8736-a56f99bdefbb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_plot(hist, show= True, save=True, path='MNIST_DCGAN_results/MNIST_DCGAN_train_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmpiCYnkxjsr"
   },
   "outputs": [],
   "source": [
    "#Fun Stuff\n",
    "images = []\n",
    "images1 = []\n",
    "\n",
    "for e in range(tr_epch):\n",
    "    img_name = 'MNIST_DCGAN_results/Fixed_results/MNIST_DCGAN_' + str(e + 1) + '.png'\n",
    "    images.append(imageio.imread(img_name))\n",
    "    \n",
    "    \n",
    "imageio.mimsave('MNIST_DCGAN_results/generation_animation_fixed.gif', images, fps=5)\n",
    "\n",
    "for e in range(tr_epch):\n",
    "    img_name = 'MNIST_DCGAN_results/Random_results/MNIST_DCGAN_' + str(e + 1) + '.png'\n",
    "    images1.append(imageio.imread(img_name))\n",
    "    \n",
    "    \n",
    "imageio.mimsave('MNIST_DCGAN_results/generation_animation_random.gif', images1, fps=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " wDCGAN-PyT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
